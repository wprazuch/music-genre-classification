{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "opj = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtzan_path = r'datasets\\gtzan'\n",
    "genres_dir = opj(gtzan_path, 'genres_original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_by_classes(dataset_path):\n",
    "    data = []\n",
    "    labels = []\n",
    "    classes = os.listdir(dataset_path)\n",
    "    for cl in tqdm(classes):\n",
    "        full_p = opj(dataset_path, cl)\n",
    "        for file in os.listdir(full_p):\n",
    "            for i in range(0, 20, 2):\n",
    "                filepath = os.path.join(full_p, file)  \n",
    "                try:\n",
    "                    wavedata, _ = librosa.load(filepath, sr=None, mono=True, offset=i, duration=2)\n",
    "                except:\n",
    "                    continue\n",
    "                wavedata = wavedata[:, np.newaxis]\n",
    "                data.append(wavedata)\n",
    "                labels.append(cl)\n",
    "\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:01<00:01,  2.71it/s]C:\\ProgramData\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\librosa\\core\\audio.py:162: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "data, labels = load_data_by_classes(genres_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9990"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizes = [len(item) for item in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = min(sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [item[:min_size] for item in data]\n",
    "\n",
    "# int(min_size/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "# data = data[..., np.newaxis]\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "labels = le.fit_transform(labels)\n",
    "labels_1hot = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9990, 44100, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BATCH_SIZE=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices((data, labels_1hot)).shuffle(4096).batch(BATCH_SIZE).prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_SIZE = len(dataset)\n",
    "\n",
    "# train_size = int(0.7 * DATASET_SIZE)\n",
    "# val_size = int(0.15 * DATASET_SIZE)\n",
    "\n",
    "# train_dataset = dataset.take(train_size)\n",
    "# val_dataset = dataset.skip(train_size)\n",
    "# test_dataset = dataset.skip(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = tf.convert_to_tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.convert_to_tensor(X_train)\n",
    "X_val = tf.convert_to_tensor(X_val)\n",
    "X_test = tf.convert_to_tensor(X_test)\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = tf.convert_to_tensor(data)\n",
    "# labels_one_hot = tf.one_hot(labels, depth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, Dropout, LSTM, TimeDistributed, Activation, Dense, Input, MaxPooling1D, Lambda, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LAYERS = 4\n",
    "CONV_FILTER_COUNT = 64\n",
    "FILTER_LENGTH = 25\n",
    "\n",
    "GENRES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9990, 44100, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow.keras import Model, Sequential\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_COUNT = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCH_COUNT = 80\n",
    "\n",
    "kernel_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(32, kernel_size, input_shape=data.shape[1:], activation='relu'))\n",
    "model.add(Conv1D(32, kernel_size, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=4)) \n",
    "\n",
    "model.add(Conv1D(32, kernel_size, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=4)) \n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu')) \n",
    "model.add(Dropout(0.5))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(10 ,activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy' , optimizer=RMSprop(learning_rate=0.0001) , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/24\n",
      "  2/213 [..............................] - ETA: 57s - loss: 2.3293 - accuracy: 0.1250WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1420s vs `on_train_batch_end` time: 0.3930s). Check your callbacks.\n",
      "213/213 [==============================] - 122s 571ms/step - loss: 2.1787 - accuracy: 0.1974 - val_loss: 2.0010 - val_accuracy: 0.2596\n",
      "Epoch 2/24\n",
      "208/213 [============================>.] - ETA: 2s - loss: 1.9612 - accuracy: 0.3101"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, validation_data=val_dataset, epochs = 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 1s 35ms/step - loss: 0.0430 - accuracy: 0.9901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04299801588058472, 0.9900990128517151]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((None, data.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = Conv1D(filters=64, kernel_size=(FILTER_LENGTH,))(inp)\n",
    "mp1 = MaxPooling1D(2)(conv1)\n",
    "act1 = Activation('relu')(mp1)\n",
    "\n",
    "\n",
    "conv2 = Conv1D(filters=128, kernel_size=(FILTER_LENGTH,))(act1)\n",
    "mp2 = MaxPooling1D(2)(conv2)\n",
    "act2 = Activation('relu')(mp1)\n",
    "\n",
    "\n",
    "conv3 = Conv1D(filters=256, kernel_size=(FILTER_LENGTH,))(act2)\n",
    "mp3 = MaxPooling1D(2)(conv3)\n",
    "act3 = Activation('relu')(mp3)\n",
    "\n",
    "layer = Dropout(0.5)(act3)\n",
    "layer = LSTM(LSTM_COUNT, return_sequences=True)(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = TimeDistributed(Dense(GENRES))(layer)\n",
    "layer = Activation('softmax', name='output_realtime')(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_distributed_merge_layer = Lambda(\n",
    "        function=lambda x: K.mean(x, axis=1),\n",
    "        output_shape=lambda shape: (shape[0],) + shape[2:],\n",
    "        name='output_merged')\n",
    "\n",
    "model_output = time_distributed_merge_layer(layer)\n",
    "model = Model(inp, model_output)\n",
    "opt = RMSprop(lr=0.00001)  # Optimizer\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(data, labels_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((data.shape[1]))\n",
    "\n",
    "layer = inp\n",
    "\n",
    "for i in range(N_LAYERS):\n",
    "    # Convolutional layer names are used by extract_filters.py\n",
    "    layer = Conv1D(\n",
    "        filters=(None, CONV_FILTER_COUNT),\n",
    "        kernel_size=(FILTER_LENGTH,),\n",
    "        name='convolution_' + str(i + 1))(layer)\n",
    "    layer = Activation('relu')(layer)\n",
    "    layer = MaxPooling1D(2)(layer)\n",
    "\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = LSTM(LSTM_COUNT, return_sequences=True)(layer)\n",
    "layer = Dropout(0.5)(layer)\n",
    "layer = TimeDistributed(Dense(len(GENRES)))(layer)\n",
    "layer = Activation('softmax', name='output_realtime')(layer)\n",
    "time_distributed_merge_layer = Lambda(\n",
    "    function=lambda x: K.mean(x, axis=1),\n",
    "    output_shape=lambda shape: (shape[0],) + shape[2:],\n",
    "    name='output_merged')\n",
    "model_output = time_distributed_merge_layer(layer)\n",
    "model = Model(model_input, model_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.00001)  # Optimizer\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
